{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain the block_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import queue\n",
    "import itertools\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the graph by the pickle file created through the RQ1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Graph\", \"rb\") as f:\n",
    "    graph = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chiasmal syndrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kleroterion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pinakion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LyndonHochschildSerre spectral sequence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zariski's main theorem</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Name\n",
       "0                        Chiasmal syndrome\n",
       "1                              Kleroterion\n",
       "2                                 Pinakion\n",
       "3  LyndonHochschildSerre spectral sequence\n",
       "4                   Zariski's main theorem"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('wiki-topcats-page-names.txt',sep='\\n', header=-1, names=[\"Name\"])\n",
    "\n",
    "#remove the index from the name:\n",
    "df[\"Name\"]=df.apply(lambda x: \" \".join(x[\"Name\"].split()[1:]),axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of nodes: 1791489\n",
      "Number of nodes by the graph: 461193\n"
     ]
    }
   ],
   "source": [
    "n=len(df)\n",
    "n_graph = graph.number_of_nodes()\n",
    "print(\"Total number of nodes:\",n)\n",
    "print(\"Number of nodes by the graph:\",n_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We oserve that the great majority of the nodes are not in the graph (isolated points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of the file containing the categories is:\n",
    "\n",
    "    Category:NameOfTheCategory; indexes of the nodes belonging to the category separeted by space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>nodes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Buprestoidea</td>\n",
       "      <td>[301, 302, 303, 304, 305, 306, 307, 308, 309, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>People_from_Worcester</td>\n",
       "      <td>[1056, 1057, 1058, 1059, 1060, 60971, 76515, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Skin_conditions_resulting_from_physical_factors</td>\n",
       "      <td>[971, 973, 1166, 1167, 1168, 1169, 1170, 1171,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Visual_kei_bands</td>\n",
       "      <td>[1297, 1300, 1311, 1312, 1313, 1314, 1315, 131...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Japanese_rock_music_groups</td>\n",
       "      <td>[1297, 1300, 1313, 1314, 1315, 1316, 1319, 132...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Name  \\\n",
       "0                                     Buprestoidea   \n",
       "1                            People_from_Worcester   \n",
       "2  Skin_conditions_resulting_from_physical_factors   \n",
       "3                                 Visual_kei_bands   \n",
       "4                       Japanese_rock_music_groups   \n",
       "\n",
       "                                               nodes  \n",
       "0  [301, 302, 303, 304, 305, 306, 307, 308, 309, ...  \n",
       "1  [1056, 1057, 1058, 1059, 1060, 60971, 76515, 7...  \n",
       "2  [971, 973, 1166, 1167, 1168, 1169, 1170, 1171,...  \n",
       "3  [1297, 1300, 1311, 1312, 1313, 1314, 1315, 131...  \n",
       "4  [1297, 1300, 1313, 1314, 1315, 1316, 1319, 132...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category = pd.read_csv(\"wiki-topcats-categories.txt\", header = None, sep = \"/n\", names=[\"all\"],engine=\"python\")\n",
    "\n",
    "#Reaching the name of the category:\n",
    "#Splitting by \";\" and the taking the first part, splitting by \":\" and taking the second part\n",
    "category[\"Name\"]=category.apply(lambda x: x[\"all\"].split(\";\")[0].split(\":\")[1], axis=1)\n",
    "\n",
    "#Reaching the list pf nodes:\n",
    "#Splitting by \":\" and taking the second part and split by \" \"\n",
    "category[\"nodes\"]= category.apply(lambda x: list(map(int,x[\"all\"].split(\";\")[1].split())),axis=1)\n",
    "\n",
    "#Just change the order of the columns and drop the columns \"all\"\n",
    "category= category[[\"Name\",\"nodes\"]]\n",
    "\n",
    "category.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can keep (as required) just the category with more than 3500 nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = category.loc[category.apply(lambda x: len(x[\"nodes\"]), axis = 1) > 3500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = len(cat)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>nodes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>English_footballers</td>\n",
       "      <td>[22860, 28411, 28961, 28979, 29264, 29573, 295...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>The_Football_League_players</td>\n",
       "      <td>[14003, 23536, 27109, 27348, 27459, 27989, 280...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>Association_football_forwards</td>\n",
       "      <td>[26876, 26877, 26879, 26887, 26892, 26904, 269...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>Association_football_goalkeepers</td>\n",
       "      <td>[26900, 26909, 26917, 26960, 26966, 26984, 270...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>Association_football_midfielders</td>\n",
       "      <td>[14003, 15291, 23536, 26880, 26882, 26885, 268...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Name  \\\n",
       "868               English_footballers   \n",
       "869       The_Football_League_players   \n",
       "876     Association_football_forwards   \n",
       "898  Association_football_goalkeepers   \n",
       "900  Association_football_midfielders   \n",
       "\n",
       "                                                 nodes  \n",
       "868  [22860, 28411, 28961, 28979, 29264, 29573, 295...  \n",
       "869  [14003, 23536, 27109, 27348, 27459, 27989, 280...  \n",
       "876  [26876, 26877, 26879, 26887, 26892, 26904, 269...  \n",
       "898  [26900, 26909, 26917, 26960, 26966, 26984, 270...  \n",
       "900  [14003, 15291, 23536, 26880, 26882, 26885, 268...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lengths=[]\n",
    "for i,val in cat.iterrows():\n",
    "    lengths.append(len(val[\"nodes\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9237,\n",
       " 9467,\n",
       " 6959,\n",
       " 3997,\n",
       " 8270,\n",
       " 6668,\n",
       " 418223,\n",
       " 3760,\n",
       " 6154,\n",
       " 6580,\n",
       " 6546,\n",
       " 5913,\n",
       " 7851,\n",
       " 3813,\n",
       " 34721,\n",
       " 7729,\n",
       " 13704,\n",
       " 5701,\n",
       " 4853,\n",
       " 3501,\n",
       " 4551,\n",
       " 22699,\n",
       " 15302,\n",
       " 3697,\n",
       " 4888,\n",
       " 3542,\n",
       " 11661,\n",
       " 13938,\n",
       " 8401,\n",
       " 12174,\n",
       " 7237,\n",
       " 6767,\n",
       " 3588,\n",
       " 4040,\n",
       " 4517]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to reduce the running time, let's take the smallest category as the input category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English_television_actors\n"
     ]
    }
   ],
   "source": [
    "idx_min =np.argmin(np.array(lengths))\n",
    "C0 = cat.iloc[idx_min][\"Name\"]\n",
    "print(C0)  #Name of the input category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3501\n"
     ]
    }
   ],
   "source": [
    "nodes_C0 = list(cat.loc[cat[\"Name\"]==C0][\"nodes\"])[0]\n",
    "print(len(nodes_C0))  #Number of its nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the function that computes the BFS. That algorithm computes the shortest path between one source node and all the other nodes of the graph for an unweighted graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breadth_first_search(G,a):\n",
    "    visited=[False]*n\n",
    "    visited[a]=True\n",
    "    q = queue.Queue()\n",
    "    q.put(a)\n",
    "    d={}\n",
    "    d[a]=0\n",
    "    while not q.empty():\n",
    "        v=q.get()\n",
    "        for i in list(G.neighbors(v)):\n",
    "            if not visited[i]:\n",
    "                q.put(i)\n",
    "                visited[i]=True\n",
    "                d[i] = d[v]+1\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "The running time of the algorithm from the library is 1.4900486469268799\n",
      "The running time of our algorithm 1.559196949005127\n"
     ]
    }
   ],
   "source": [
    "a = time.time()\n",
    "bfs1 =nx.single_source_shortest_path_length(G=graph,source=52)\n",
    "b = time.time()\n",
    "our_bfs =breadth_first_search(graph, 52)\n",
    "c = time.time()\n",
    "print(bfs1 == our_bfs)\n",
    "print(\"The running time of the algorithm from the library is\",b-a)\n",
    "print(\"The running time of our algorithm\",c-b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our BFS is identical to the algorithm from the library (so it is correct). Also we see that the running times are very similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to compute the dictionary of the distances (using BFS) with source every node belonging to the category $C_0$. \n",
    "\n",
    "We would create a dictionary of this format:\n",
    "\n",
    "- The key are all the nodes of the graph\n",
    "- For each key the value is a list, where each element is the lenght of the shortest path with one of the nodes of the category $C_0$\n",
    "\n",
    "But we would encounter a memory error (the previous dictionary has about 400k keys, each one with value a list of about 3.5k elements).\n",
    "\n",
    "Then we store as values (instead of a list) a nested dictionary, with keys the distances and values the FREQUENCIES with which each distance appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! This cell would take 2 hours, DO NOT RUN IT !!!\n",
    "# Instead if you want you can upload the \"final_dict\" (2 cells later)\n",
    "\n",
    "final_dict=dict((i,{}) for i in graph.nodes)\n",
    "for i in nodes_C0:\n",
    "    if i in graph:\n",
    "        d = breadth_first_search(graph,i)\n",
    "        for j in d:\n",
    "            final_dict[j][d[j]] = final_dict[j].get(d[j],0) +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"final_dict\",\"wb\") as f:\n",
    "    pickle.dump(final_dict,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"final_dict\",\"rb\") as f:\n",
    "    final_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how it looks like, just for two nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{95: {5: 1835, 6: 1080, 4: 266, 7: 59, 3: 4, 8: 2, 9: 1},\n",
       " 103: {},\n",
       " 104: {6: 1771, 5: 1236, 7: 160, 8: 13, 4: 64, 3: 2, 9: 1}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{95: final_dict[95], 103:final_dict[103], 104:final_dict[104]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for each category $C_i$, we can easily obtain the __ShortestPath($C_0$,$C_i$)__ just taking all the dictionaries for every node belonging to $C_i$, and merging them.\n",
    "\n",
    "Once obtained the set  ShortestPath($C_0$,$C_i$), we just need to take the median of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could compute the median using `statistics.median`, but in the code of that function it is used sorted(list) instead of list.sort().\n",
    "\n",
    "Now the problem is that for the category Living_people which has 400k nodes, the list shortest_path is very large, and if we use sorted() we are creating a copy of this, that could create a __Memory error__. So we have to create a little function to compute the median by ourself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median(l):\n",
    "    l.sort()\n",
    "    middle = len(l)//2\n",
    "    return l[middle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "medians={}\n",
    "list_of_names = cat.loc[cat[\"Name\"]!=C0][\"Name\"]\n",
    "for Ci in list_of_names:\n",
    "    nodes_Ci = list(cat.loc[cat[\"Name\"]==Ci][\"nodes\"])[0]\n",
    "    shortest_path=[]\n",
    "    for node in nodes_Ci:\n",
    "        try:\n",
    "            d = final_dict[node]\n",
    "            for lenght in d:\n",
    "                shortest_path.extend(d[lenght]*[lenght])\n",
    "        except:\n",
    "            continue\n",
    "    medians[Ci]= median(shortest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'English_footballers': 6,\n",
       " 'The_Football_League_players': 6,\n",
       " 'Association_football_forwards': 6,\n",
       " 'Association_football_goalkeepers': 6,\n",
       " 'Association_football_midfielders': 6,\n",
       " 'Association_football_defenders': 6,\n",
       " 'Living_people': 6,\n",
       " 'Year_of_birth_unknown': 6,\n",
       " 'Harvard_University_alumni': 6,\n",
       " 'Major_League_Baseball_pitchers': 6,\n",
       " 'Members_of_the_United_Kingdom_Parliament_for_English_constituencies': 6,\n",
       " 'Indian_films': 6,\n",
       " 'Year_of_death_missing': 6,\n",
       " 'English_cricketers': 6,\n",
       " 'Year_of_birth_missing_(living_people)': 6,\n",
       " 'Rivers_of_Romania': 7,\n",
       " 'Main_Belt_asteroids': 8,\n",
       " 'Asteroids_named_for_people': 7,\n",
       " 'English-language_albums': 5,\n",
       " 'British_films': 5,\n",
       " 'English-language_films': 5,\n",
       " 'American_films': 5,\n",
       " 'Fellows_of_the_Royal_Society': 6,\n",
       " 'People_from_New_York_City': 5,\n",
       " 'American_Jews': 5,\n",
       " 'American_television_actors': 5,\n",
       " 'American_film_actors': 5,\n",
       " 'Debut_albums': 6,\n",
       " 'Black-and-white_films': 5,\n",
       " 'Year_of_birth_missing': 6,\n",
       " 'Place_of_birth_missing_(living_people)': 6,\n",
       " 'Article_Feedback_Pilot': 5,\n",
       " 'American_military_personnel_of_World_War_II': 5,\n",
       " 'Windows_games': 6}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"medians\",\"wb\") as f:\n",
    "    pickle.dump(medians,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"medians\",\"rb\") as f:\n",
    "    medians = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just sort the dictionary by values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_ranking = [C0]+[k for k, v in sorted(medians.items(), key=lambda x: x[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['English_television_actors',\n",
       " 'English-language_albums',\n",
       " 'British_films',\n",
       " 'English-language_films',\n",
       " 'American_films',\n",
       " 'People_from_New_York_City',\n",
       " 'American_Jews',\n",
       " 'American_television_actors',\n",
       " 'American_film_actors',\n",
       " 'Black-and-white_films',\n",
       " 'Article_Feedback_Pilot',\n",
       " 'American_military_personnel_of_World_War_II',\n",
       " 'English_footballers',\n",
       " 'The_Football_League_players',\n",
       " 'Association_football_forwards',\n",
       " 'Association_football_goalkeepers',\n",
       " 'Association_football_midfielders',\n",
       " 'Association_football_defenders',\n",
       " 'Living_people',\n",
       " 'Year_of_birth_unknown',\n",
       " 'Harvard_University_alumni',\n",
       " 'Major_League_Baseball_pitchers',\n",
       " 'Members_of_the_United_Kingdom_Parliament_for_English_constituencies',\n",
       " 'Indian_films',\n",
       " 'Year_of_death_missing',\n",
       " 'English_cricketers',\n",
       " 'Year_of_birth_missing_(living_people)',\n",
       " 'Fellows_of_the_Royal_Society',\n",
       " 'Debut_albums',\n",
       " 'Year_of_birth_missing',\n",
       " 'Place_of_birth_missing_(living_people)',\n",
       " 'Windows_games',\n",
       " 'Rivers_of_Romania',\n",
       " 'Asteroids_named_for_people',\n",
       " 'Main_Belt_asteroids']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort the nodes in each category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting take a look that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool=False\n",
    "for i in final_dict:\n",
    "    if i not in graph:\n",
    "        bool = True\n",
    "        break\n",
    "bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no nodes reached by some node (in `final_dict`), but without retiring edges (not in `graph`, since we builded it in this way)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, first of all we need to keep every node just to one category, the closest to the input category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English_television_actors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English-language_albums</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>British_films</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>English-language_films</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>American_films</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Name\n",
       "0  English_television_actors\n",
       "1    English-language_albums\n",
       "2              British_films\n",
       "3     English-language_films\n",
       "4             American_films"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newCat =pd.DataFrame(block_ranking,columns=[\"Name\"])\n",
    "newCat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "already_seen=set() #keep the list of the nodes already seen, starting by C0\n",
    "nodes2 = []\n",
    "for i,categ in enumerate(block_ranking): #C0,C1,....\n",
    "    idx = cat.loc[cat[\"Name\"]==C0].index[0] #take the index\n",
    "    updated_nodes = []\n",
    "    for node in list(cat.loc[cat[\"Name\"]==categ][\"nodes\"])[0]:\n",
    "        if (node not in already_seen) and (node in graph):  #remove as well nodes not in graph\n",
    "            already_seen.add(node)\n",
    "            updated_nodes.append(node)\n",
    "    nodes2.append(updated_nodes)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>nodes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English_television_actors</td>\n",
       "      <td>[32782, 40338, 40566, 53495, 72636, 83294, 840...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English-language_albums</td>\n",
       "      <td>[185, 186, 40523, 40524, 40525, 40528, 60647, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>British_films</td>\n",
       "      <td>[214, 1084, 23768, 28836, 30602, 30714, 35063,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>English-language_films</td>\n",
       "      <td>[134, 153, 1083, 1087, 1089, 1152, 1158, 1178,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>American_films</td>\n",
       "      <td>[173, 1131, 13360, 14130, 14138, 15933, 17458,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Name  \\\n",
       "0  English_television_actors   \n",
       "1    English-language_albums   \n",
       "2              British_films   \n",
       "3     English-language_films   \n",
       "4             American_films   \n",
       "\n",
       "                                               nodes  \n",
       "0  [32782, 40338, 40566, 53495, 72636, 83294, 840...  \n",
       "1  [185, 186, 40523, 40524, 40525, 40528, 60647, ...  \n",
       "2  [214, 1084, 23768, 28836, 30602, 30714, 35063,...  \n",
       "3  [134, 153, 1083, 1087, 1089, 1152, 1158, 1178,...  \n",
       "4  [173, 1131, 13360, 14130, 14138, 15933, 17458,...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newCat[\"nodes\"]=nodes2\n",
    "newCat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {i:1 for i in graph.nodes}\n",
    "for ind,value in newCat.iterrows():\n",
    "    nodes = value[1]\n",
    "    subgraph = graph.subgraph(nodes)\n",
    "    newWeights={}\n",
    "    for node in nodes:\n",
    "        edges = list(subgraph.in_edges(node))\n",
    "        newWeights[node] = sum([weights[i[1]] for i in edges])\n",
    "    #update weights\n",
    "    for j in newWeights:\n",
    "        weights[j] = newWeights[j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created the weight for each node, now we just need to sort each category using those weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank=[]\n",
    "for ind,value in newCat.iterrows():\n",
    "    nodes = value[1]\n",
    "    #obtain the dictionary d of weights just for these nodes:\n",
    "    d={}\n",
    "    for node in nodes:\n",
    "        d[node] = weights[node]\n",
    "    #sort the dictionary d by values and keep just the keys:\n",
    "    rank_i =[k for k, v in sorted(d.items(), key=lambda x: x[1])]\n",
    "    Rank.extend(rank_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "461193"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just observe that is the same as number of nodes found in RQ1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
